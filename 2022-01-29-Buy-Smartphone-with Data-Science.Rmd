---
title: "Buy Smartphone with Data Science"
author: "Ramon Roldan"
date: "2022-01-29"
categories: [Data Science, Tydeverse]
tags: [Text Mining, Web Scraping, Tydeverse, Data Science, ETL, Strategic Sourcing, Procurement, Supply Chain]
output:
  md_document:
    variant: gfm
    preserve_yaml: TRUE
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "/home/ramon_de_lara/Ramon/roldanramon.github.io/_posts") })
---

```{r, include=FALSE}
#Clear the environment and load the libraries
rm(list = ls())
library(dplyr)
library(rvest)
library(tibble)
library(janitor)
library(tidyr)
library(knitr)
library(purrr)
library(DT)
```

This post has the main objective to sharing my experience with a business case, where i pretend tell how i buyed a new smartphone using the data science and strategic sourcing techniques.

In jan/2021 i needed buy a new smartphone, then I thinking with me: Why not using data science to develop a machine learning model to help me?

[This project is divide in 5 parts:]{.ul}

1. Getting the data by web scraping;
2. Cleaning the data;
3. Start an exploratory analysis in the data;
4. Setting the "weights" and create a model to help filter some devices;
5. Conclusion: choosing "the best" device.

### 1. Getting the data by web scraping
Reading the main URL to obtain data about html page and then start web scraping process:
```{r}
aparelhos<- tibble::tibble(url = unique(paste('https://www.tudocelular.com', rvest::read_html('https://www.tudocelular.com/celulares/fichas-tecnicas.html') %>% rvest::html_elements(xpath = '//*[@id="cellphones_list"]/article') %>% rvest::html_nodes('a') %>% rvest::html_attr('href'),sep = ''))) %>%
  dplyr::filter(stringr::str_detect(string = url, pattern = 'ficha')) %>% dplyr::mutate(url = as.character(url))
slice_head(aparelhos,n = 5)
```

Developing of function to do web scraping and then obtain the data about each device:
```{r, echo=TRUE}
fun_to_get_info <- function(phone) {
  
  url_link<- rvest::read_html(as.character(phone))
  
  telefone <-tibble::tibble(
    nomes = url_link %>% rvest::html_elements(xpath = '//*[@id="controles_titles"]') %>% rvest::html_nodes('li') %>% rvest::html_text() %>% readr::parse_character(),
    atributos = ifelse(
      !is.na(url_link %>% rvest::html_elements(xpath = '//*[@id="phone_columns"]') %>% rvest::html_nodes('li') %>% rvest::html_text() %>% readr::parse_character()),
      url_link %>% rvest::html_elements(xpath = '//*[@id="phone_columns"]') %>% rvest::html_nodes('li') %>% rvest::html_text() %>% readr::parse_character(),
      url_link %>% rvest::html_elements(xpath = '//*[@id="phone_columns"]') %>% rvest::html_nodes('li') %>% rvest::html_node('i') %>% rvest::html_attr('class') %>% readr::parse_character()
    )
  ) %>% 
    dplyr::mutate('Nome do Aparelho' = url_link %>% rvest::html_elements(xpath = '//*[@id="fwide_column"]/h2') %>% rvest::html_text())
  return(telefone)
}
```

Apply function to do download the data and presentation on the beautiful table:
```{r}
htop<- purrr::map_dfr(.x = aparelhos$url, .f = fun_to_get_info) %>% 
  tidyr::pivot_wider(names_from = 'nomes', values_from = atributos, values_fn = list) %>% janitor::clean_names() %>% as_tibble()

knitr::kable(x = slice_head(htop,n = 5),
             caption = "The top Devices")
```

### 2. Cleaning the data
```{r}

```


### 3. Start an exploratory analysis in the data

### 4. Setting the "weights" and create a model to help filter some devices

### 5. Conclusion: choosing "the best" device
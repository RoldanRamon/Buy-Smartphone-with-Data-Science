---
title: "Buy Smartphone with Data Science"
author: "Ramon Roldan"
date: "2022-01-29"
categories:
  - Data Science
  - Tydeverse
tags:
  - Text Mining
  - Web Scraping
  - Tydeverse
  - Data Science
  - ETL
description: 'This post has the main objective to sharing my experience with a business case, where i pretend tell how i buyed a new smartphone using the data science techniques.'

output:
  blogdown::html_page:
    toc: true
    toc_depth: 2
---

```{=html}
<style>
.column {
float: left;
width: 50%;
padding: 10px;
}

.column4 {
float: left;
width: 33%;
padding: 10px;
}

.column8 {
float: left;
width: 66%;
padding: 10px;
}

.row:after {
content: "";
display: table;
clear: both;
}

.center {
display: flex;
justify-content: center;
align-items: center;
height: 200px;
}
</style>
```
```{r, include=FALSE}
#Clear the environment and load the libraries
rm(list = ls())
library(dplyr)
library(rvest)
library(tibble)
library(janitor)
library(DT)
```

This post has the main objective to sharing my experience with a business case, where i pretend tell how i buyed a new smartphone using the data science techniques.

In jan/2021 i needed buy a new smartphone, then I thinking with me: Why not using data science to develop a machine learning model to help me?

[This project is divide in 5 parts:]{.ul}

1. Getting the data by web scraping;
2. Cleaning the data;
3. Start an exploratory analysis in the data;
4. Setting the "weights" and create a model to help filter some devices;
5. Conclusion: choosing "the best" device.

### 1. Getting the data by web scraping
Reading the main URL to obtain data about html page and then start web scraping process
```{r}
aparelhos<- tibble::tibble(url = unique(paste('https://www.tudocelular.com', rvest::read_html('https://www.tudocelular.com/celulares/fichas-tecnicas.html') %>% rvest::html_elements(xpath = '//*[@id="cellphones_list"]/article') %>% rvest::html_nodes('a') %>% rvest::html_attr('href'),sep = ''))) %>%
  dplyr::filter(stringr::str_detect(string = url, pattern = 'ficha')) %>% dplyr::mutate(url = as.character(url))
aparelhos
```

Developing of function to do web scraping and then obtain the data about each device
```{r, echo=TRUE}
fun_to_get_info <- function(phone) {
  
  url_link<- rvest::read_html(as.character(phone))
  
  telefone <-tibble::tibble(
    nomes = url_link %>% rvest::html_elements(xpath = '//*[@id="controles_titles"]') %>% rvest::html_nodes('li') %>% rvest::html_text() %>% readr::parse_character(),
    atributos = ifelse(
      !is.na(url_link %>% rvest::html_elements(xpath = '//*[@id="phone_columns"]') %>% rvest::html_nodes('li') %>% rvest::html_text() %>% readr::parse_character()),
      url_link %>% rvest::html_elements(xpath = '//*[@id="phone_columns"]') %>% rvest::html_nodes('li') %>% rvest::html_text() %>% readr::parse_character(),
      url_link %>% rvest::html_elements(xpath = '//*[@id="phone_columns"]') %>% rvest::html_nodes('li') %>% rvest::html_node('i') %>% rvest::html_attr('class') %>% readr::parse_character()
    )
  ) %>% 
    dplyr::mutate('Nome do Aparelho' = url_link %>% rvest::html_elements(xpath = '//*[@id="fwide_column"]/h2') %>% rvest::html_text())
  return(telefone)
}

```

Apply function to do download the data and presentation on the beautiful table
```{r}
htop<- purrr::map_dfr(.x = aparelhos$url, .f = fun_to_get_info) %>% 
  tidyr::pivot_wider(names_from = 'nomes', values_from = atributos, values_fn = list) %>% janitor::clean_names()

knitr::kable(x = slice(htop, 1:5),
             caption = "The top Devices")
```

### 2. Cleaning the data

### 3. Start an exploratory analysis in the data

### 4. Setting the "weights" and create a model to help filter some devices

### 5. Conclusion: choosing "the best" device